2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - __main__ - INFO - GenAI Fraud Detection Pipeline Coordinator
2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - __main__ - INFO - 
2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - __main__ - INFO - SYSTEM INFORMATION
2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - __main__ - INFO - PyTorch Version: 2.6.0+cu124
2025-12-28 00:59:33 - __main__ - INFO - CUDA Available: Yes
2025-12-28 00:59:33 - __main__ - INFO - CUDA Version: 12.4
2025-12-28 00:59:33 - __main__ - INFO - GPU Count: 1
2025-12-28 00:59:33 - __main__ - INFO - GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU
2025-12-28 00:59:33 - __main__ - INFO -   Memory: 4.29 GB
2025-12-28 00:59:33 - __main__ - INFO - 
2025-12-28 00:59:33 - __main__ - INFO - 
2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - __main__ - INFO - [STEP1] PII CLEANING
2025-12-28 00:59:33 - __main__ - INFO - ================================================================================
2025-12-28 00:59:33 - pii_cleaner - INFO - Loading all datasets...
2025-12-28 00:59:33 - pii_cleaner - INFO - Loaded Base.csv: 50000 rows (sampled)
2025-12-28 00:59:33 - pii_cleaner - INFO - Loaded Variant I.csv: 50000 rows (sampled)
2025-12-28 00:59:33 - pii_cleaner - INFO - Loaded Variant II.csv: 50000 rows (sampled)
2025-12-28 00:59:34 - pii_cleaner - INFO - Loaded Variant III.csv: 50000 rows (sampled)
2025-12-28 00:59:34 - pii_cleaner - INFO - Loaded Variant IV.csv: 50000 rows (sampled)
2025-12-28 00:59:34 - pii_cleaner - INFO - Loaded Variant V.csv: 50000 rows (sampled)
2025-12-28 00:59:34 - pii_cleaner - INFO - Cleaning PII from all datasets...
2025-12-28 00:59:34 - pii_cleaner - INFO - Cleaning PII from Base
2025-12-28 00:59:35 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Base_clean.csv
2025-12-28 00:59:35 - pii_cleaner - INFO - Cleaning PII from Variant I
2025-12-28 00:59:36 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Variant I_clean.csv
2025-12-28 00:59:36 - pii_cleaner - INFO - Cleaning PII from Variant II
2025-12-28 00:59:37 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Variant II_clean.csv
2025-12-28 00:59:37 - pii_cleaner - INFO - Cleaning PII from Variant III
2025-12-28 00:59:39 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Variant III_clean.csv
2025-12-28 00:59:39 - pii_cleaner - INFO - Cleaning PII from Variant IV
2025-12-28 00:59:40 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Variant IV_clean.csv
2025-12-28 00:59:40 - pii_cleaner - INFO - Cleaning PII from Variant V
2025-12-28 00:59:41 - pii_cleaner - INFO - Saved cleaned dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\Variant V_clean.csv
2025-12-28 00:59:41 - pii_cleaner - INFO - Combining all cleaned datasets...
2025-12-28 00:59:41 - pii_cleaner - INFO - Combined datasets into 300000 rows
2025-12-28 00:59:48 - pii_cleaner - INFO - Saved combined clean dataset: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_data_combined_clean.csv
2025-12-28 00:59:48 - __main__ - INFO - 
2025-12-28 00:59:48 - __main__ - INFO - ================================================================================
2025-12-28 00:59:48 - __main__ - INFO - [STEP2] FRAUD NARRATIVE GENERATION
2025-12-28 00:59:48 - __main__ - INFO - ================================================================================
2025-12-28 00:59:48 - genai_narrative_generator - INFO - Loading data from C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_data_combined_clean.csv
2025-12-28 00:59:50 - genai_narrative_generator - INFO - Generating narratives for 5000 transactions
2025-12-28 00:59:50 - genai_narrative_generator - INFO - Augmenting narratives with fraud patterns
2025-12-28 00:59:50 - genai_narrative_generator - INFO - Saved 5000 narratives to C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_narratives_combined.csv
2025-12-28 00:59:50 - genai_narrative_generator - INFO - Narrative generation complete: 5000 narratives
2025-12-28 00:59:50 - __main__ - INFO - 
2025-12-28 00:59:50 - __main__ - INFO - ================================================================================
2025-12-28 00:59:50 - __main__ - INFO - [STEP3] FRAUD EMBEDDING MODEL
2025-12-28 00:59:50 - __main__ - INFO - ================================================================================
2025-12-28 00:59:50 - genai_embedding_model - INFO - Loading narratives from C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_narratives_combined.csv
2025-12-28 00:59:51 - genai_embedding_model - INFO - Loaded 5000 narratives
2025-12-28 00:59:51 - genai_embedding_model - INFO - Using device: cuda:0
2025-12-28 00:59:51 - genai_embedding_model - INFO - GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2025-12-28 00:59:51 - genai_embedding_model - INFO - CUDA Version: 12.4
2025-12-28 00:59:51 - genai_embedding_model - INFO - GPU Memory: 4.29 GB
2025-12-28 00:59:51 - genai_embedding_model - INFO - GPU memory cache cleared for optimization
2025-12-28 00:59:51 - genai_embedding_model - INFO - PyTorch Version: 2.6.0+cu124
2025-12-28 00:59:51 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-12-28 00:59:51 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /distilbert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-12-28 00:59:51 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/distilbert-base-uncased/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 146
2025-12-28 00:59:51 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/distilbert/distilbert-base-uncased/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-12-28 00:59:52 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/distilbert-base-uncased/tree/main?recursive=True&expand=False HTTP/1.1" 307 119
2025-12-28 00:59:52 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/distilbert/distilbert-base-uncased/tree/main?recursive=True&expand=False HTTP/1.1" 200 2197
2025-12-28 00:59:52 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /distilbert-base-uncased/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 00:59:52 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /distilbert-base-uncased/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 00:59:53 - genai_embedding_model - INFO - Training model for 3 epochs with batch_size=16
2025-12-28 00:59:58 - genai_embedding_model - INFO - Epoch 1 [10] Loss: 0.0167
2025-12-28 01:00:04 - genai_embedding_model - INFO - Epoch 1 [20] Loss: 0.0101
2025-12-28 01:00:09 - genai_embedding_model - INFO - Epoch 1 [30] Loss: 0.0048
2025-12-28 01:00:14 - genai_embedding_model - INFO - Epoch 1 [40] Loss: 0.0051
2025-12-28 01:00:20 - genai_embedding_model - INFO - Epoch 1 [50] Loss: 0.0151
2025-12-28 01:00:25 - genai_embedding_model - INFO - Epoch 1 [60] Loss: 0.0101
2025-12-28 01:00:31 - genai_embedding_model - INFO - Epoch 1 [70] Loss: 0.0236
2025-12-28 01:00:37 - genai_embedding_model - INFO - Epoch 1 [80] Loss: 0.0042
2025-12-28 01:00:42 - genai_embedding_model - INFO - Epoch 1 [90] Loss: 0.0164
2025-12-28 01:00:48 - genai_embedding_model - INFO - Epoch 1 [100] Loss: 0.0011
2025-12-28 01:00:55 - genai_embedding_model - INFO - Epoch 1 [110] Loss: 0.0047
2025-12-28 01:01:01 - genai_embedding_model - INFO - Epoch 1 [120] Loss: 0.0007
2025-12-28 01:01:08 - genai_embedding_model - INFO - Epoch 1 [130] Loss: 0.0006
2025-12-28 01:01:15 - genai_embedding_model - INFO - Epoch 1 [140] Loss: 0.0005
2025-12-28 01:01:22 - genai_embedding_model - INFO - Epoch 1 [150] Loss: 0.0005
2025-12-28 01:01:30 - genai_embedding_model - INFO - Epoch 1 [160] Loss: 0.0004
2025-12-28 01:01:38 - genai_embedding_model - INFO - Epoch 1 [170] Loss: 0.0010
2025-12-28 01:01:45 - genai_embedding_model - INFO - Epoch 1 [180] Loss: 0.0004
2025-12-28 01:01:53 - genai_embedding_model - INFO - Epoch 1 [190] Loss: 0.0008
2025-12-28 01:02:02 - genai_embedding_model - INFO - Epoch 1 [200] Loss: 0.0003
2025-12-28 01:02:11 - genai_embedding_model - INFO - Epoch 1 [210] Loss: 0.0003
2025-12-28 01:02:20 - genai_embedding_model - INFO - Epoch 1 [220] Loss: 0.0003
2025-12-28 01:02:31 - genai_embedding_model - INFO - Epoch 1 [230] Loss: 0.0002
2025-12-28 01:02:42 - genai_embedding_model - INFO - Epoch 1 [240] Loss: 0.0002
2025-12-28 01:02:54 - genai_embedding_model - INFO - Epoch 1 [250] Loss: 0.0002
2025-12-28 01:03:07 - genai_embedding_model - INFO - Epoch 1 [260] Loss: 0.0002
2025-12-28 01:03:19 - genai_embedding_model - INFO - Epoch 1 [270] Loss: 0.0002
2025-12-28 01:03:32 - genai_embedding_model - INFO - Epoch 1 [280] Loss: 0.0002
2025-12-28 01:03:45 - genai_embedding_model - INFO - Epoch 1 [290] Loss: 0.0002
2025-12-28 01:03:59 - genai_embedding_model - INFO - Epoch 1 [300] Loss: 0.0002
2025-12-28 01:04:13 - genai_embedding_model - INFO - Epoch 1 [310] Loss: 0.0001
2025-12-28 01:04:16 - genai_embedding_model - INFO - Epoch 1 completed - Avg Loss: 0.0217
2025-12-28 01:04:32 - genai_embedding_model - INFO - Epoch 2 [10] Loss: 0.0001
2025-12-28 01:04:47 - genai_embedding_model - INFO - Epoch 2 [20] Loss: 0.0003
2025-12-28 01:05:02 - genai_embedding_model - INFO - Epoch 2 [30] Loss: 0.0001
2025-12-28 01:05:19 - genai_embedding_model - INFO - Epoch 2 [40] Loss: 0.0001
2025-12-28 01:05:36 - genai_embedding_model - INFO - Epoch 2 [50] Loss: 0.0003
2025-12-28 01:05:53 - genai_embedding_model - INFO - Epoch 2 [60] Loss: 0.0001
2025-12-28 01:06:11 - genai_embedding_model - INFO - Epoch 2 [70] Loss: 0.0001
2025-12-28 01:06:30 - genai_embedding_model - INFO - Epoch 2 [80] Loss: 0.0001
2025-12-28 01:06:49 - genai_embedding_model - INFO - Epoch 2 [90] Loss: 0.0001
2025-12-28 01:07:07 - genai_embedding_model - INFO - Epoch 2 [100] Loss: 0.0001
2025-12-28 01:07:26 - genai_embedding_model - INFO - Epoch 2 [110] Loss: 0.0001
2025-12-28 01:07:47 - genai_embedding_model - INFO - Epoch 2 [120] Loss: 0.0001
2025-12-28 01:08:09 - genai_embedding_model - INFO - Epoch 2 [130] Loss: 0.0002
2025-12-28 01:08:30 - genai_embedding_model - INFO - Epoch 2 [140] Loss: 0.0001
2025-12-28 01:08:52 - genai_embedding_model - INFO - Epoch 2 [150] Loss: 0.0001
2025-12-28 01:09:11 - genai_embedding_model - INFO - Epoch 2 [160] Loss: 0.0001
2025-12-28 01:09:30 - genai_embedding_model - INFO - Epoch 2 [170] Loss: 0.0001
2025-12-28 01:09:50 - genai_embedding_model - INFO - Epoch 2 [180] Loss: 0.0001
2025-12-28 01:10:11 - genai_embedding_model - INFO - Epoch 2 [190] Loss: 0.0001
2025-12-28 01:10:31 - genai_embedding_model - INFO - Epoch 2 [200] Loss: 0.0001
2025-12-28 01:10:50 - genai_embedding_model - INFO - Epoch 2 [210] Loss: 0.0001
2025-12-28 01:11:08 - genai_embedding_model - INFO - Epoch 2 [220] Loss: 0.0001
2025-12-28 01:11:28 - genai_embedding_model - INFO - Epoch 2 [230] Loss: 0.0002
2025-12-28 01:11:48 - genai_embedding_model - INFO - Epoch 2 [240] Loss: 0.0001
2025-12-28 01:12:09 - genai_embedding_model - INFO - Epoch 2 [250] Loss: 0.0001
2025-12-28 01:12:30 - genai_embedding_model - INFO - Epoch 2 [260] Loss: 0.0001
2025-12-28 01:12:51 - genai_embedding_model - INFO - Epoch 2 [270] Loss: 0.0001
2025-12-28 01:13:13 - genai_embedding_model - INFO - Epoch 2 [280] Loss: 0.0001
2025-12-28 01:13:34 - genai_embedding_model - INFO - Epoch 2 [290] Loss: 0.0001
2025-12-28 01:13:55 - genai_embedding_model - INFO - Epoch 2 [300] Loss: 0.0001
2025-12-28 01:14:16 - genai_embedding_model - INFO - Epoch 2 [310] Loss: 0.0003
2025-12-28 01:14:21 - genai_embedding_model - INFO - Epoch 2 completed - Avg Loss: 0.0001
2025-12-28 01:14:43 - genai_embedding_model - INFO - Epoch 3 [10] Loss: 0.0001
2025-12-28 01:15:04 - genai_embedding_model - INFO - Epoch 3 [20] Loss: 0.0000
2025-12-28 01:15:25 - genai_embedding_model - INFO - Epoch 3 [30] Loss: 0.0001
2025-12-28 01:15:47 - genai_embedding_model - INFO - Epoch 3 [40] Loss: 0.0001
2025-12-28 01:16:08 - genai_embedding_model - INFO - Epoch 3 [50] Loss: 0.0001
2025-12-28 01:16:29 - genai_embedding_model - INFO - Epoch 3 [60] Loss: 0.0001
2025-12-28 01:16:50 - genai_embedding_model - INFO - Epoch 3 [70] Loss: 0.0001
2025-12-28 01:17:12 - genai_embedding_model - INFO - Epoch 3 [80] Loss: 0.0000
2025-12-28 01:17:33 - genai_embedding_model - INFO - Epoch 3 [90] Loss: 0.0000
2025-12-28 01:17:54 - genai_embedding_model - INFO - Epoch 3 [100] Loss: 0.0001
2025-12-28 01:18:16 - genai_embedding_model - INFO - Epoch 3 [110] Loss: 0.0000
2025-12-28 01:18:37 - genai_embedding_model - INFO - Epoch 3 [120] Loss: 0.0000
2025-12-28 01:18:58 - genai_embedding_model - INFO - Epoch 3 [130] Loss: 0.0002
2025-12-28 01:19:21 - genai_embedding_model - INFO - Epoch 3 [140] Loss: 0.0000
2025-12-28 01:19:45 - genai_embedding_model - INFO - Epoch 3 [150] Loss: 0.0000
2025-12-28 01:20:08 - genai_embedding_model - INFO - Epoch 3 [160] Loss: 0.0001
2025-12-28 01:20:30 - genai_embedding_model - INFO - Epoch 3 [170] Loss: 0.0000
2025-12-28 01:20:51 - genai_embedding_model - INFO - Epoch 3 [180] Loss: 0.0001
2025-12-28 01:21:12 - genai_embedding_model - INFO - Epoch 3 [190] Loss: 0.0000
2025-12-28 01:21:34 - genai_embedding_model - INFO - Epoch 3 [200] Loss: 0.0000
2025-12-28 01:21:57 - genai_embedding_model - INFO - Epoch 3 [210] Loss: 0.0000
2025-12-28 01:22:19 - genai_embedding_model - INFO - Epoch 3 [220] Loss: 0.0000
2025-12-28 01:22:38 - genai_embedding_model - INFO - Epoch 3 [230] Loss: 0.0001
2025-12-28 01:23:04 - genai_embedding_model - INFO - Epoch 3 [240] Loss: 0.0000
2025-12-28 01:23:28 - genai_embedding_model - INFO - Epoch 3 [250] Loss: 0.0000
2025-12-28 01:23:51 - genai_embedding_model - INFO - Epoch 3 [260] Loss: 0.0000
2025-12-28 01:24:15 - genai_embedding_model - INFO - Epoch 3 [270] Loss: 0.0000
2025-12-28 01:24:37 - genai_embedding_model - INFO - Epoch 3 [280] Loss: 0.0000
2025-12-28 01:25:01 - genai_embedding_model - INFO - Epoch 3 [290] Loss: 0.0000
2025-12-28 01:25:24 - genai_embedding_model - INFO - Epoch 3 [300] Loss: 0.0000
2025-12-28 01:25:48 - genai_embedding_model - INFO - Epoch 3 [310] Loss: 0.0000
2025-12-28 01:25:54 - genai_embedding_model - INFO - Epoch 3 completed - Avg Loss: 0.0001
2025-12-28 01:25:54 - genai_embedding_model - INFO - Extracting embeddings for all narratives
2025-12-28 01:30:00 - genai_embedding_model - INFO - Saved embeddings: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_embeddings.pkl
2025-12-28 01:30:01 - genai_embedding_model - INFO - Saved model: C:\Users\anshu\GenAI-Powered Fraud Detection System\models\fraud_embedding_model.pt
2025-12-28 01:30:01 - genai_embedding_model - INFO - Saved tokenizer: C:\Users\anshu\GenAI-Powered Fraud Detection System\models\embedding_tokenizer
2025-12-28 01:30:01 - __main__ - INFO - 
2025-12-28 01:30:01 - __main__ - INFO - ================================================================================
2025-12-28 01:30:01 - __main__ - INFO - [STEP4] GPT-2 LoRA FINE-TUNING
2025-12-28 01:30:01 - __main__ - INFO - ================================================================================
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - Loading narratives from C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_narratives_combined.csv
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - Loaded 5000 narratives
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - Using device: cuda:0
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - GPU: NVIDIA GeForce RTX 3050 Laptop GPU
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - CUDA Version: 12.4
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - GPU Memory: 4.29 GB
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - GPU memory cache cleared for optimization
2025-12-28 01:30:01 - fraud_gpt_trainer - INFO - PyTorch Version: 2.6.0+cu124
2025-12-28 01:30:01 - urllib3.connectionpool - DEBUG - Resetting dropped connection: huggingface.co
2025-12-28 01:30:01 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-12-28 01:30:01 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 133
2025-12-28 01:30:02 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-12-28 01:30:02 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/gpt2/tree/main?recursive=True&expand=False HTTP/1.1" 307 106
2025-12-28 01:30:02 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/openai-community/gpt2/tree/main?recursive=True&expand=False HTTP/1.1" 200 4996
2025-12-28 01:30:03 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 01:30:03 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 01:30:03 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-12-28 01:30:03 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-12-28 01:30:04 - fraud_gpt_trainer - INFO - LoRA adapter applied to GPT-2
2025-12-28 01:30:04 - fraud_gpt_trainer - INFO - Training GPT-2 LoRA for 3 epochs with batch_size=8
2025-12-28 01:30:31 - fraud_gpt_trainer - INFO - Epoch 1 [10] Loss: 8.2731
2025-12-28 01:30:59 - fraud_gpt_trainer - INFO - Epoch 1 [20] Loss: 7.4653
2025-12-28 01:31:27 - fraud_gpt_trainer - INFO - Epoch 1 [30] Loss: 6.7086
2025-12-28 01:31:54 - fraud_gpt_trainer - INFO - Epoch 1 [40] Loss: 5.8087
2025-12-28 01:32:22 - fraud_gpt_trainer - INFO - Epoch 1 [50] Loss: 4.6671
2025-12-28 01:32:49 - fraud_gpt_trainer - INFO - Epoch 1 [60] Loss: 3.3586
2025-12-28 01:33:17 - fraud_gpt_trainer - INFO - Epoch 1 [70] Loss: 1.6239
2025-12-28 01:33:45 - fraud_gpt_trainer - INFO - Epoch 1 [80] Loss: 1.0767
2025-12-28 01:34:10 - fraud_gpt_trainer - INFO - Epoch 1 [90] Loss: 0.9810
2025-12-28 01:34:34 - fraud_gpt_trainer - INFO - Epoch 1 [100] Loss: 0.9325
2025-12-28 01:35:00 - fraud_gpt_trainer - INFO - Epoch 1 [110] Loss: 0.8879
2025-12-28 01:35:26 - fraud_gpt_trainer - INFO - Epoch 1 [120] Loss: 0.9600
2025-12-28 01:35:54 - fraud_gpt_trainer - INFO - Epoch 1 [130] Loss: 0.8636
2025-12-28 01:36:19 - fraud_gpt_trainer - INFO - Epoch 1 [140] Loss: 0.9012
2025-12-28 01:36:43 - fraud_gpt_trainer - INFO - Epoch 1 [150] Loss: 0.8291
2025-12-28 01:37:09 - fraud_gpt_trainer - INFO - Epoch 1 [160] Loss: 0.8741
2025-12-28 01:37:33 - fraud_gpt_trainer - INFO - Epoch 1 [170] Loss: 0.8468
2025-12-28 01:37:58 - fraud_gpt_trainer - INFO - Epoch 1 [180] Loss: 0.8654
2025-12-28 01:38:22 - fraud_gpt_trainer - INFO - Epoch 1 [190] Loss: 0.8034
2025-12-28 01:38:46 - fraud_gpt_trainer - INFO - Epoch 1 [200] Loss: 0.8608
2025-12-28 01:39:10 - fraud_gpt_trainer - INFO - Epoch 1 [210] Loss: 0.8169
2025-12-28 01:39:35 - fraud_gpt_trainer - INFO - Epoch 1 [220] Loss: 0.7327
2025-12-28 01:39:59 - fraud_gpt_trainer - INFO - Epoch 1 [230] Loss: 0.7949
2025-12-28 01:40:23 - fraud_gpt_trainer - INFO - Epoch 1 [240] Loss: 0.7852
2025-12-28 01:40:47 - fraud_gpt_trainer - INFO - Epoch 1 [250] Loss: 0.7319
2025-12-28 01:41:11 - fraud_gpt_trainer - INFO - Epoch 1 [260] Loss: 0.7177
2025-12-28 01:41:34 - fraud_gpt_trainer - INFO - Epoch 1 [270] Loss: 0.7419
2025-12-28 01:41:58 - fraud_gpt_trainer - INFO - Epoch 1 [280] Loss: 0.6506
2025-12-28 01:42:23 - fraud_gpt_trainer - INFO - Epoch 1 [290] Loss: 0.7382
2025-12-28 01:42:47 - fraud_gpt_trainer - INFO - Epoch 1 [300] Loss: 0.6766
2025-12-28 01:43:11 - fraud_gpt_trainer - INFO - Epoch 1 [310] Loss: 0.6141
2025-12-28 01:43:35 - fraud_gpt_trainer - INFO - Epoch 1 [320] Loss: 0.6585
2025-12-28 01:43:59 - fraud_gpt_trainer - INFO - Epoch 1 [330] Loss: 0.6749
2025-12-28 01:44:22 - fraud_gpt_trainer - INFO - Epoch 1 [340] Loss: 0.6553
2025-12-28 01:44:47 - fraud_gpt_trainer - INFO - Epoch 1 [350] Loss: 0.6177
2025-12-28 01:45:15 - fraud_gpt_trainer - INFO - Epoch 1 [360] Loss: 0.5570
2025-12-28 01:45:42 - fraud_gpt_trainer - INFO - Epoch 1 [370] Loss: 0.5764
2025-12-28 01:46:10 - fraud_gpt_trainer - INFO - Epoch 1 [380] Loss: 0.5980
2025-12-28 01:46:38 - fraud_gpt_trainer - INFO - Epoch 1 [390] Loss: 0.5516
2025-12-28 01:47:05 - fraud_gpt_trainer - INFO - Epoch 1 [400] Loss: 0.5245
2025-12-28 01:47:33 - fraud_gpt_trainer - INFO - Epoch 1 [410] Loss: 0.5013
2025-12-28 01:48:00 - fraud_gpt_trainer - INFO - Epoch 1 [420] Loss: 0.4777
2025-12-28 01:48:28 - fraud_gpt_trainer - INFO - Epoch 1 [430] Loss: 0.5814
2025-12-28 01:48:56 - fraud_gpt_trainer - INFO - Epoch 1 [440] Loss: 0.5048
2025-12-28 01:49:23 - fraud_gpt_trainer - INFO - Epoch 1 [450] Loss: 0.4673
2025-12-28 01:49:50 - fraud_gpt_trainer - INFO - Epoch 1 [460] Loss: 0.4951
2025-12-28 01:50:16 - fraud_gpt_trainer - INFO - Epoch 1 [470] Loss: 0.4049
2025-12-28 01:50:42 - fraud_gpt_trainer - INFO - Epoch 1 [480] Loss: 0.4050
2025-12-28 01:51:07 - fraud_gpt_trainer - INFO - Epoch 1 [490] Loss: 0.4183
2025-12-28 01:51:31 - fraud_gpt_trainer - INFO - Epoch 1 [500] Loss: 0.3509
2025-12-28 01:51:58 - fraud_gpt_trainer - INFO - Epoch 1 [510] Loss: 0.3287
2025-12-28 01:52:26 - fraud_gpt_trainer - INFO - Epoch 1 [520] Loss: 0.3273
2025-12-28 01:52:54 - fraud_gpt_trainer - INFO - Epoch 1 [530] Loss: 0.2905
2025-12-28 01:53:22 - fraud_gpt_trainer - INFO - Epoch 1 [540] Loss: 0.2909
2025-12-28 01:53:49 - fraud_gpt_trainer - INFO - Epoch 1 [550] Loss: 0.2785
2025-12-28 01:54:17 - fraud_gpt_trainer - INFO - Epoch 1 [560] Loss: 0.2790
2025-12-28 01:54:44 - fraud_gpt_trainer - INFO - Epoch 1 [570] Loss: 0.2444
2025-12-28 01:55:12 - fraud_gpt_trainer - INFO - Epoch 1 [580] Loss: 0.2292
2025-12-28 01:55:39 - fraud_gpt_trainer - INFO - Epoch 1 [590] Loss: 0.2359
2025-12-28 01:56:02 - fraud_gpt_trainer - INFO - Epoch 1 [600] Loss: 0.2320
2025-12-28 01:56:27 - fraud_gpt_trainer - INFO - Epoch 1 [610] Loss: 0.2288
2025-12-28 01:56:55 - fraud_gpt_trainer - INFO - Epoch 1 [620] Loss: 0.2084
2025-12-28 01:57:08 - fraud_gpt_trainer - INFO - Epoch 1 completed - Avg Loss: 1.1946
2025-12-28 01:57:36 - fraud_gpt_trainer - INFO - Epoch 2 [10] Loss: 0.2088
2025-12-28 01:58:04 - fraud_gpt_trainer - INFO - Epoch 2 [20] Loss: 0.2300
2025-12-28 01:58:31 - fraud_gpt_trainer - INFO - Epoch 2 [30] Loss: 0.1894
2025-12-28 01:58:52 - fraud_gpt_trainer - INFO - Epoch 2 [40] Loss: 0.1894
2025-12-28 01:59:04 - fraud_gpt_trainer - INFO - Epoch 2 [50] Loss: 0.1907
2025-12-28 01:59:16 - fraud_gpt_trainer - INFO - Epoch 2 [60] Loss: 0.2042
2025-12-28 01:59:27 - fraud_gpt_trainer - INFO - Epoch 2 [70] Loss: 0.1782
2025-12-28 01:59:38 - fraud_gpt_trainer - INFO - Epoch 2 [80] Loss: 0.1692
2025-12-28 01:59:49 - fraud_gpt_trainer - INFO - Epoch 2 [90] Loss: 0.1801
2025-12-28 01:59:59 - fraud_gpt_trainer - INFO - Epoch 2 [100] Loss: 0.1533
2025-12-28 02:00:09 - fraud_gpt_trainer - INFO - Epoch 2 [110] Loss: 0.1618
2025-12-28 02:00:20 - fraud_gpt_trainer - INFO - Epoch 2 [120] Loss: 0.1433
2025-12-28 02:00:30 - fraud_gpt_trainer - INFO - Epoch 2 [130] Loss: 0.1538
2025-12-28 02:00:40 - fraud_gpt_trainer - INFO - Epoch 2 [140] Loss: 0.1463
2025-12-28 02:00:50 - fraud_gpt_trainer - INFO - Epoch 2 [150] Loss: 0.1564
2025-12-28 02:00:59 - fraud_gpt_trainer - INFO - Epoch 2 [160] Loss: 0.1373
2025-12-28 02:01:09 - fraud_gpt_trainer - INFO - Epoch 2 [170] Loss: 0.1421
2025-12-28 02:01:19 - fraud_gpt_trainer - INFO - Epoch 2 [180] Loss: 0.1356
2025-12-28 02:01:29 - fraud_gpt_trainer - INFO - Epoch 2 [190] Loss: 0.1587
2025-12-28 02:01:40 - fraud_gpt_trainer - INFO - Epoch 2 [200] Loss: 0.1164
2025-12-28 02:01:50 - fraud_gpt_trainer - INFO - Epoch 2 [210] Loss: 0.1995
2025-12-28 02:02:00 - fraud_gpt_trainer - INFO - Epoch 2 [220] Loss: 0.1344
2025-12-28 02:02:09 - fraud_gpt_trainer - INFO - Epoch 2 [230] Loss: 0.1365
2025-12-28 02:02:19 - fraud_gpt_trainer - INFO - Epoch 2 [240] Loss: 0.1242
2025-12-28 02:02:28 - fraud_gpt_trainer - INFO - Epoch 2 [250] Loss: 0.1294
2025-12-28 02:02:38 - fraud_gpt_trainer - INFO - Epoch 2 [260] Loss: 0.1238
2025-12-28 02:02:47 - fraud_gpt_trainer - INFO - Epoch 2 [270] Loss: 0.1189
2025-12-28 02:02:57 - fraud_gpt_trainer - INFO - Epoch 2 [280] Loss: 0.1273
2025-12-28 02:03:06 - fraud_gpt_trainer - INFO - Epoch 2 [290] Loss: 0.1359
2025-12-28 02:03:16 - fraud_gpt_trainer - INFO - Epoch 2 [300] Loss: 0.1305
2025-12-28 02:03:25 - fraud_gpt_trainer - INFO - Epoch 2 [310] Loss: 0.1362
2025-12-28 02:03:35 - fraud_gpt_trainer - INFO - Epoch 2 [320] Loss: 0.1127
2025-12-28 02:03:45 - fraud_gpt_trainer - INFO - Epoch 2 [330] Loss: 0.1050
2025-12-28 02:03:54 - fraud_gpt_trainer - INFO - Epoch 2 [340] Loss: 0.1099
2025-12-28 02:04:04 - fraud_gpt_trainer - INFO - Epoch 2 [350] Loss: 0.1076
2025-12-28 02:04:13 - fraud_gpt_trainer - INFO - Epoch 2 [360] Loss: 0.0790
2025-12-28 02:04:23 - fraud_gpt_trainer - INFO - Epoch 2 [370] Loss: 0.1097
2025-12-28 02:04:32 - fraud_gpt_trainer - INFO - Epoch 2 [380] Loss: 0.1156
2025-12-28 02:04:42 - fraud_gpt_trainer - INFO - Epoch 2 [390] Loss: 0.1163
2025-12-28 02:04:51 - fraud_gpt_trainer - INFO - Epoch 2 [400] Loss: 0.1935
2025-12-28 02:05:01 - fraud_gpt_trainer - INFO - Epoch 2 [410] Loss: 0.1097
2025-12-28 02:05:10 - fraud_gpt_trainer - INFO - Epoch 2 [420] Loss: 0.1123
2025-12-28 02:05:20 - fraud_gpt_trainer - INFO - Epoch 2 [430] Loss: 0.1070
2025-12-28 02:05:29 - fraud_gpt_trainer - INFO - Epoch 2 [440] Loss: 0.1208
2025-12-28 02:05:39 - fraud_gpt_trainer - INFO - Epoch 2 [450] Loss: 0.1160
2025-12-28 02:05:49 - fraud_gpt_trainer - INFO - Epoch 2 [460] Loss: 0.1110
2025-12-28 02:05:58 - fraud_gpt_trainer - INFO - Epoch 2 [470] Loss: 0.1187
2025-12-28 02:06:08 - fraud_gpt_trainer - INFO - Epoch 2 [480] Loss: 0.1126
2025-12-28 02:06:19 - fraud_gpt_trainer - INFO - Epoch 2 [490] Loss: 0.1149
2025-12-28 02:06:29 - fraud_gpt_trainer - INFO - Epoch 2 [500] Loss: 0.0995
2025-12-28 02:06:38 - fraud_gpt_trainer - INFO - Epoch 2 [510] Loss: 0.1065
2025-12-28 02:06:48 - fraud_gpt_trainer - INFO - Epoch 2 [520] Loss: 0.0929
2025-12-28 02:06:57 - fraud_gpt_trainer - INFO - Epoch 2 [530] Loss: 0.1126
2025-12-28 02:07:07 - fraud_gpt_trainer - INFO - Epoch 2 [540] Loss: 0.1083
2025-12-28 02:07:17 - fraud_gpt_trainer - INFO - Epoch 2 [550] Loss: 0.0903
2025-12-28 02:07:27 - fraud_gpt_trainer - INFO - Epoch 2 [560] Loss: 0.0999
2025-12-28 02:07:38 - fraud_gpt_trainer - INFO - Epoch 2 [570] Loss: 0.0911
2025-12-28 02:07:48 - fraud_gpt_trainer - INFO - Epoch 2 [580] Loss: 0.1209
2025-12-28 02:07:59 - fraud_gpt_trainer - INFO - Epoch 2 [590] Loss: 0.1510
2025-12-28 02:08:09 - fraud_gpt_trainer - INFO - Epoch 2 [600] Loss: 0.1096
2025-12-28 02:08:20 - fraud_gpt_trainer - INFO - Epoch 2 [610] Loss: 0.1045
2025-12-28 02:08:30 - fraud_gpt_trainer - INFO - Epoch 2 [620] Loss: 0.1037
2025-12-28 02:08:35 - fraud_gpt_trainer - INFO - Epoch 2 completed - Avg Loss: 0.1380
2025-12-28 02:08:46 - fraud_gpt_trainer - INFO - Epoch 3 [10] Loss: 0.1039
2025-12-28 02:08:57 - fraud_gpt_trainer - INFO - Epoch 3 [20] Loss: 0.1477
2025-12-28 02:09:07 - fraud_gpt_trainer - INFO - Epoch 3 [30] Loss: 0.1052
2025-12-28 02:09:18 - fraud_gpt_trainer - INFO - Epoch 3 [40] Loss: 0.0998
2025-12-28 02:09:29 - fraud_gpt_trainer - INFO - Epoch 3 [50] Loss: 0.0998
2025-12-28 02:09:39 - fraud_gpt_trainer - INFO - Epoch 3 [60] Loss: 0.0842
2025-12-28 02:09:50 - fraud_gpt_trainer - INFO - Epoch 3 [70] Loss: 0.1011
2025-12-28 02:10:02 - fraud_gpt_trainer - INFO - Epoch 3 [80] Loss: 0.0880
2025-12-28 02:10:14 - fraud_gpt_trainer - INFO - Epoch 3 [90] Loss: 0.1208
2025-12-28 02:10:26 - fraud_gpt_trainer - INFO - Epoch 3 [100] Loss: 0.0989
2025-12-28 02:10:38 - fraud_gpt_trainer - INFO - Epoch 3 [110] Loss: 0.1148
2025-12-28 02:10:50 - fraud_gpt_trainer - INFO - Epoch 3 [120] Loss: 0.0884
2025-12-28 02:11:00 - fraud_gpt_trainer - INFO - Epoch 3 [130] Loss: 0.1005
2025-12-28 02:11:11 - fraud_gpt_trainer - INFO - Epoch 3 [140] Loss: 0.1005
2025-12-28 02:11:21 - fraud_gpt_trainer - INFO - Epoch 3 [150] Loss: 0.0990
2025-12-28 02:11:32 - fraud_gpt_trainer - INFO - Epoch 3 [160] Loss: 0.0813
2025-12-28 02:11:43 - fraud_gpt_trainer - INFO - Epoch 3 [170] Loss: 0.0824
2025-12-28 02:11:53 - fraud_gpt_trainer - INFO - Epoch 3 [180] Loss: 0.0813
2025-12-28 02:12:04 - fraud_gpt_trainer - INFO - Epoch 3 [190] Loss: 0.0783
2025-12-28 02:12:15 - fraud_gpt_trainer - INFO - Epoch 3 [200] Loss: 0.1025
2025-12-28 02:12:26 - fraud_gpt_trainer - INFO - Epoch 3 [210] Loss: 0.0904
2025-12-28 02:12:36 - fraud_gpt_trainer - INFO - Epoch 3 [220] Loss: 0.0841
2025-12-28 02:12:47 - fraud_gpt_trainer - INFO - Epoch 3 [230] Loss: 0.0856
2025-12-28 02:12:58 - fraud_gpt_trainer - INFO - Epoch 3 [240] Loss: 0.1015
2025-12-28 02:13:09 - fraud_gpt_trainer - INFO - Epoch 3 [250] Loss: 0.0883
2025-12-28 02:13:20 - fraud_gpt_trainer - INFO - Epoch 3 [260] Loss: 0.0976
2025-12-28 02:13:31 - fraud_gpt_trainer - INFO - Epoch 3 [270] Loss: 0.0795
2025-12-28 02:13:41 - fraud_gpt_trainer - INFO - Epoch 3 [280] Loss: 0.0833
2025-12-28 02:13:52 - fraud_gpt_trainer - INFO - Epoch 3 [290] Loss: 0.0837
2025-12-28 02:14:04 - fraud_gpt_trainer - INFO - Epoch 3 [300] Loss: 0.0862
2025-12-28 02:14:16 - fraud_gpt_trainer - INFO - Epoch 3 [310] Loss: 0.0943
2025-12-28 02:14:28 - fraud_gpt_trainer - INFO - Epoch 3 [320] Loss: 0.0820
2025-12-28 02:14:39 - fraud_gpt_trainer - INFO - Epoch 3 [330] Loss: 0.0925
2025-12-28 02:14:50 - fraud_gpt_trainer - INFO - Epoch 3 [340] Loss: 0.0935
2025-12-28 02:15:00 - fraud_gpt_trainer - INFO - Epoch 3 [350] Loss: 0.0857
2025-12-28 02:15:11 - fraud_gpt_trainer - INFO - Epoch 3 [360] Loss: 0.0924
2025-12-28 02:15:22 - fraud_gpt_trainer - INFO - Epoch 3 [370] Loss: 0.0882
2025-12-28 02:15:32 - fraud_gpt_trainer - INFO - Epoch 3 [380] Loss: 0.0988
2025-12-28 02:15:43 - fraud_gpt_trainer - INFO - Epoch 3 [390] Loss: 0.0902
2025-12-28 02:15:54 - fraud_gpt_trainer - INFO - Epoch 3 [400] Loss: 0.0934
2025-12-28 02:16:05 - fraud_gpt_trainer - INFO - Epoch 3 [410] Loss: 0.0891
2025-12-28 02:16:16 - fraud_gpt_trainer - INFO - Epoch 3 [420] Loss: 0.0697
2025-12-28 02:16:26 - fraud_gpt_trainer - INFO - Epoch 3 [430] Loss: 0.0812
2025-12-28 02:16:37 - fraud_gpt_trainer - INFO - Epoch 3 [440] Loss: 0.0815
2025-12-28 02:16:48 - fraud_gpt_trainer - INFO - Epoch 3 [450] Loss: 0.1219
2025-12-28 02:16:59 - fraud_gpt_trainer - INFO - Epoch 3 [460] Loss: 0.0944
2025-12-28 02:17:10 - fraud_gpt_trainer - INFO - Epoch 3 [470] Loss: 0.0866
2025-12-28 02:17:21 - fraud_gpt_trainer - INFO - Epoch 3 [480] Loss: 0.0834
2025-12-28 02:17:32 - fraud_gpt_trainer - INFO - Epoch 3 [490] Loss: 0.0875
2025-12-28 02:17:44 - fraud_gpt_trainer - INFO - Epoch 3 [500] Loss: 0.0854
2025-12-28 02:17:55 - fraud_gpt_trainer - INFO - Epoch 3 [510] Loss: 0.1010
2025-12-28 02:18:06 - fraud_gpt_trainer - INFO - Epoch 3 [520] Loss: 0.0948
2025-12-28 02:18:17 - fraud_gpt_trainer - INFO - Epoch 3 [530] Loss: 0.1123
2025-12-28 02:18:28 - fraud_gpt_trainer - INFO - Epoch 3 [540] Loss: 0.0772
2025-12-28 02:18:38 - fraud_gpt_trainer - INFO - Epoch 3 [550] Loss: 0.0812
2025-12-28 02:18:49 - fraud_gpt_trainer - INFO - Epoch 3 [560] Loss: 0.0838
2025-12-28 02:19:00 - fraud_gpt_trainer - INFO - Epoch 3 [570] Loss: 0.0907
2025-12-28 02:19:11 - fraud_gpt_trainer - INFO - Epoch 3 [580] Loss: 0.0854
2025-12-28 02:19:22 - fraud_gpt_trainer - INFO - Epoch 3 [590] Loss: 0.1359
2025-12-28 02:19:33 - fraud_gpt_trainer - INFO - Epoch 3 [600] Loss: 0.0670
2025-12-28 02:19:44 - fraud_gpt_trainer - INFO - Epoch 3 [610] Loss: 0.0952
2025-12-28 02:19:55 - fraud_gpt_trainer - INFO - Epoch 3 [620] Loss: 0.1146
2025-12-28 02:20:00 - fraud_gpt_trainer - INFO - Epoch 3 completed - Avg Loss: 0.0954
2025-12-28 02:20:00 - urllib3.connectionpool - DEBUG - Resetting dropped connection: huggingface.co
2025-12-28 02:20:00 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 02:20:01 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-12-28 02:20:01 - fraud_gpt_trainer - INFO - Saved LoRA adapter: C:\Users\anshu\GenAI-Powered Fraud Detection System\models\fraud_pattern_generator_lora
2025-12-28 02:20:01 - fraud_gpt_trainer - INFO - Saved tokenizer: C:\Users\anshu\GenAI-Powered Fraud Detection System\models\gpt2_tokenizer
2025-12-28 02:20:01 - fraud_gpt_trainer - INFO - GPT-2 LoRA fine-tuning completed
2025-12-28 02:20:01 - __main__ - INFO - 
2025-12-28 02:20:01 - __main__ - INFO - ================================================================================
2025-12-28 02:20:01 - __main__ - INFO - PIPELINE SUMMARY
2025-12-28 02:20:01 - __main__ - INFO - ================================================================================
2025-12-28 02:20:01 - __main__ - INFO -   Output: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_data_combined_clean.csv
2025-12-28 02:20:01 - __main__ - INFO -   Output: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_narratives_combined.csv
2025-12-28 02:20:01 - __main__ - INFO -   Output: C:\Users\anshu\GenAI-Powered Fraud Detection System\generated\fraud_embeddings.pkl
2025-12-28 02:20:01 - __main__ - INFO -   Output: C:\Users\anshu\GenAI-Powered Fraud Detection System\models\fraud_pattern_generator_lora
2025-12-28 02:20:01 - __main__ - INFO - Total Time: 1:20:28.142599
2025-12-28 02:20:01 - __main__ - INFO - Log File: logs\genai_pipeline_20251228_005933.log
2025-12-28 02:20:01 - __main__ - INFO - 
2025-12-28 02:20:01 - __main__ - INFO - ================================================================================
2025-12-28 02:20:01 - __main__ - INFO - ================================================================================
